{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoS0NzsjI02mbZAtDPCHiV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zarinhadika/ML/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch pandas --quiet\n"
      ],
      "metadata": {
        "id": "a3GNlgby2uQN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the faith-sensitive dataset\n",
        "df = pd.read_csv(\"/content/faith_dataset.csv\")  # Upload the CSV in Colab\n",
        "prompts = df['prompt'].tolist()\n",
        "responses = df['response'].tolist()\n"
      ],
      "metadata": {
        "id": "g4xZH0GcFONM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Free small model for demonstration\n",
        "model_name = \"bigscience/bloomz-560m\"  # You can change to other HF models\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB16fTNfIZ_F",
        "outputId": "23516803-7356-41f3-ffd5-33ebb66bcd19"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BloomForCausalLM(\n",
              "  (transformer): BloomModel(\n",
              "    (word_embeddings): Embedding(250880, 1024)\n",
              "    (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x BloomBlock(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): BloomAttention(\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): BloomMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (gelu_impl): BloomGelu()\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def faith_filter(text):\n",
        "    forbidden_words = [\"violence\", \"curse\", \"forbidden_topic\"]\n",
        "    for word in forbidden_words:\n",
        "        if word in text.lower():\n",
        "            return \"⚠️ Output flagged as potentially non-faith-aligned.\"\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "tguiyJgfIzq2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt, max_length=150):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=max_length)\n",
        "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return faith_filter(text)\n"
      ],
      "metadata": {
        "id": "M47a0v1CJMQs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts[:5]:  # Test first 5 prompts\n",
        "    print(\"Prompt:\", prompt)\n",
        "    print(\"AI Response:\", generate_response(prompt))\n",
        "    print(\"-\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs_bh8nIJTWz",
        "outputId": "a21d9ee0-d477-40ed-f8bf-95779147f120"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: What is the Islamic view on honesty?\n",
            "AI Response: What is the Islamic view on honesty? the principle of honesty\n",
            "--------------------------------------------------\n",
            "Prompt: Can we eat halal food?\n",
            "AI Response: Can we eat halal food? Yes\n",
            "--------------------------------------------------\n",
            "Prompt: How should I deal with anger?\n",
            "AI Response: How should I deal with anger? calm\n",
            "--------------------------------------------------\n",
            "Prompt: Is gossiping allowed?\n",
            "AI Response: Is gossiping allowed? Yes\n",
            "--------------------------------------------------\n",
            "Prompt: What should I do if I find lost money?\n",
            "AI Response: What should I do if I find lost money? I should get a refund\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt, max_length=150):\n",
        "    # Few-shot examples from your dataset\n",
        "    examples = \"\"\"\n",
        "Q: What is the Islamic view on honesty?\n",
        "A: Honesty is highly valued in Islam; lying is forbidden and honesty builds trust.\n",
        "\n",
        "Q: Can we eat halal food?\n",
        "A: Yes, food must comply with Islamic dietary laws to be halal.\n",
        "\n",
        "Q: How should I deal with anger?\n",
        "A: Islam encourages patience and forgiveness when you feel angry.\n",
        "\"\"\"\n",
        "    full_prompt = examples + f\"\\nQ: {prompt}\\nA:\"\n",
        "\n",
        "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=max_length, do_sample=True, temperature=0.7)\n",
        "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract only the generated answer after the last \"A:\"\n",
        "    if \"A:\" in text:\n",
        "        text = text.split(\"A:\")[-1].strip()\n",
        "    return faith_filter(text)\n"
      ],
      "metadata": {
        "id": "VMVlX4IEKqyL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts[:5]:  # Test first 5 prompts\n",
        "    print(\"Prompt:\", prompt)\n",
        "    print(\"AI Response:\", generate_response(prompt))\n",
        "    print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV4QAhVnKvWq",
        "outputId": "a7530866-767d-4946-a082-f25780657eeb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: What is the Islamic view on honesty?\n",
            "AI Response: Islam encourages patience and forgiveness when you feel angry.\n",
            "--------------------------------------------------\n",
            "Prompt: Can we eat halal food?\n",
            "AI Response: Yes, food must comply with Islamic dietary laws to be halal.\n",
            "--------------------------------------------------\n",
            "Prompt: How should I deal with anger?\n",
            "AI Response: Islam encourages patience and forgiveness when you feel angry.\n",
            "--------------------------------------------------\n",
            "Prompt: Is gossiping allowed?\n",
            "AI Response: Yes, Islam encourages patience and forgiveness when you feel angry.\n",
            "--------------------------------------------------\n",
            "Prompt: What should I do if I find lost money?\n",
            "AI Response: Islam encourages patience and forgiveness\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}